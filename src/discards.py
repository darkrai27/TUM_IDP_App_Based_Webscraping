import requests
import json
from time import sleep
from dotenv import load_dotenv
import os
from users import queryuser
from userSchemas import Json2

load_dotenv()
headers = {
  'authority': 'www.threads.net',
  'accept': '*/*',
  'accept-language': 'es-ES,es;q=0.7',
  'content-type': 'application/x-www-form-urlencoded',
  'origin': 'https://www.threads.net',
  'referer': 'https://www.threads.net/search',
  'sec-ch-ua': '"Chromium";v="116", "Not)A;Brand";v="24", "Brave";v="116"',
  'sec-ch-ua-mobile': '?0',
  'sec-ch-ua-model': '""',
  'sec-ch-ua-platform': '"macOS"',
  'sec-ch-ua-platform-version': '"13.4.0"',
  'sec-fetch-dest': 'empty',
  'sec-fetch-mode': 'cors',
  'sec-fetch-site': 'same-origin',
  'sec-gpc': '1',
  'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'
}

# users.py
def scrap_all_posts(username: str, dtsg: str = None, session_id: str = None, limit:int = None, delay: int = 5):
  '''
  Returns all posts or the most recent ones up to a specified limit of
  certain user using its internal user_id to perform the recursive queries.
  Each query is performed with certain delay to avoid banning the account for bot activity.

  Args:
    username (str): unique username of the user
    dtsg (str): Value generated by Facebook to validated the session
    session_id (str): Cookie identifier for the user session
    limit (int): Limit of posts to query. From most recent to older. None by default
    delay (int): Delay in seconds between each recursive query to avoid accounts suspensions for bot activity. 5 by default

  Returns:
    Json: All posts of the user contained in the "edges" list.
  '''

  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")

  profile = queryuser(username, dtsg, session_id)

  profile = Json2.model_validate_json(profile)

  user_id = profile.data.xdt_user_by_username.pk

  data = {
    'fb_dtsg': dtsg,
    'variables': f'{{"userID": "{user_id}"}}',
    'doc_id': '23980155134932173',
  }
  cookies = {
    'sessionid': session_id,
  }

  response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
  response = json.loads(response.text)
  cursor = response["data"]["mediaData"]["page_info"]["end_cursor"]
  res = response

  while True and (limit == None or limit > 0) and cursor != None:
    data = {
      'fb_dtsg': dtsg,
      'variables': f'{{"userID": "{user_id}", "first": "10", "after": "{response["data"]["mediaData"]["page_info"]["end_cursor"]}"}}',
      'doc_id': '23980155134932173',
    }
    response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
    response = json.loads(response.text)
    cursor = response["data"]["mediaData"]["page_info"]["end_cursor"]
    
    if len(response["data"]["mediaData"]["edges"]) > 0:
      res["data"]["mediaData"]["edges"].extend(response["data"]["mediaData"]["edges"])
    else:
      break

    if limit != None:
      limit -= len(response["data"]["mediaData"]["edges"])
    sleep(5)
  
  res["data"]["mediaData"]["page_info"] = response["data"]["mediaData"]["page_info"]

  print(len(res["data"]["mediaData"]["edges"]))
  return res

def scrap_all_reposts(username: str, dtsg: str = None, session_id: str = None, limit:int = None, delay: int = 5):
  '''
  Returns all posts or the most recent ones up to a specified limit of
  certain user using its internal user_id to perform the recursive queries.
  Each query is performed with certain delay to avoid banning the account for bot activity.
  Similar to get_posts but por reposted content from other users.


  Args:
    username (str): unique username of the user
    dtsg (str): Value generated by Facebook to validated the session
    session_id (str): Cookie identifier for the user session
    limit (int): Limit of posts to query. From most recent to older. None by default
    delay (int): Delay in seconds between each recursive query to avoid accounts suspensions for bot activity. 5 by default

  Returns:
    Json: All posts of the user contained in the "edges" list.
  '''
  pass

def scrap_all_replys(username: str, dtsg: str = None, session_id: str = None, limit:int = None, delay: int = 5):
  '''
  Crawls all replys of a user to other user's posts
  and the original posts it was replying.
  Each query is performed with certain delay to avoid banning the account for bot activity.

  Args:
    username (str): unique username of the user
    dtsg (str): Value generated by Facebook to validated the session
    session_id (str): Cookie identifier for the user session
    limit (int): Limit of posts to query. From most recent to older. None by default
    delay (int): Delay in seconds between each recursive query to avoid accounts suspensions for bot activity. 5 by default

  Returns:
    List[Edge]: List of "Edges" objects containing in each node at least 2 "thread items" being the first
    a post by other user and the seconf the reply from the specified user
  '''
  pass
