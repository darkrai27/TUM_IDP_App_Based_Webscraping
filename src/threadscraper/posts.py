from functools import singledispatch
import requests
from pydantic import Json
from time import sleep
import json
import os
from dotenv import load_dotenv

from threadscraper.postSchemas import ThreadsData, Likers

load_dotenv()

headers = {
    'authority': 'www.threads.net',
    'accept': '*/*',
    'accept-language': 'es-ES,es;q=0.7',
    'content-type': 'application/x-www-form-urlencoded',
    'origin': 'https://www.threads.net',
    'referer': 'https://www.threads.net/search',
    'sec-ch-ua': '"Chromium";v="116", "Not)A;Brand";v="24", "Brave";v="116"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-model': '""',
    'sec-ch-ua-platform': '"macOS"',
    'sec-ch-ua-platform-version': '"13.4.0"',
    'sec-fetch-dest': 'empty',
    'sec-fetch-mode': 'cors',
    'sec-fetch-site': 'same-origin',
    'sec-gpc': '1',
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'
  }
  
def get_post_info(url:str, dtsg: str = None, session_id: str = None) -> Json:
  """
  Gets basic information about a post using its URL.
  Useful to obtain the postID to use in other queries.

  Args:
    url (str): URL of the post.
    dtsg (str): Value generated by Meta to validated the session.
    session_id (str): Cookie identifier for the user session.

  Returns:
    Json: Json object containing the basic information of the post.
  """


  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")

  assert dtsg != None and session_id != None, "dtsg and session_id are required"

  cookies = {
      'sessionid': session_id,
  }

  data = {
      'route_urls[0]': url,
      '__a': '1',
      '__comet_req': '29',
      'fb_dtsg': dtsg,
  }

  response = requests.post('https://www.threads.net/ajax/bulk-route-definitions/', cookies=cookies, headers=headers, data=data)

  res = "{" + response.text.split("for (;;);{")[1]
  print(res)

  res = json.loads(res)["payload"]["payloads"][url]

  if "redirect_result" in res["result"]:
    return res["result"]["redirect_result"]["exports"]
  else:
    return  res["result"]["exports"]

def get_thread(postID: int, n: int = 100, delay: int = 1, dtsg: str = None, session_id: str = None) -> Json:

  '''
  Gets a thread, consisting of the original posts and all replies to this post and the replies by the author.

  Args:
    postID (int): Unique numerical identifier of a post.
    n (int): Maximum amount of replies to query.
    delay (int): Delay among requests to avoid the account of getting suspended by bot activity.
    dtsg (str): Value generated by Meta to validated the session.
    session_id (str): Cookie identifier for the user session.

  Returns:
    Json (ThreadsData): List of objects containing all information about a thread, its different posts and replies
  '''


  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")

  data = {
      'fb_dtsg': dtsg,
      'variables': f'{{"postID":"{postID}"}}',
      'doc_id': '6607085376050279',
  }
  cookies = {
    'sessionid': session_id,
  } 


  response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
  print(response.text)
  res = json.loads(response.text)['data']['data']
  res = ThreadsData.model_validate_json(json.dumps(res, ensure_ascii=False))
  return res.model_dump(mode='json', exclude_unset=True)

def get_thread_by_url(url: str, n: int = 100, delay: int = 1, dtsg: str = None, session_id: str = None) -> Json:

  '''
  Gets a thread, consisting of the original posts and all replies to this post and the replies by the author.

  Args:
    url (str): URL of the post.
    n (int): Maximum amount of replies to query.
    delay (int): Delay among requests to avoid the account of getting suspended by bot activity.
    dtsg (str): Value generated by Meta to validated the session.
    session_id (str): Cookie identifier for the user session.

  Returns:
    Json (ThreadsData): List of objects containing all information about a thread, its different posts and replies
  '''


  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")

  postID = get_post_info(url, dtsg, session_id)["rootView"]["props"]["post_id"]

  return get_thread(postID, n, delay, dtsg, session_id)

def get_likers(postID: int, n: int = 100, delay: int = 1, dtsg: str = None, session_id: str = None) -> Json:

  '''
  Collects all (or up to n) likers of a post, sorted by most recent.

  Args:
    postID (int): Unique numerical identifier of a post.
    n (int): Maximum amount of likers to return.
    dtsg (str): Value generated by Meta to validated the session.
    session_id (str): Cookie identifier for the user session.
    limit (int): Limit size of threads to crawl.
    delay (int): Delay among requests to avoid the account of getting suspended by bot activity.

  Returns:
     Json (List (User)): List of users object containing information about users who liked the post
  '''


  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")

  cookies = {
    'sessionid': session_id,
  }

  data = {
    'fb_dtsg': dtsg,
    'variables': f'{{"first":10,"post_id":"{postID}","request_data":{{"sort_type":"most_recent","tab_type":"like"}}}}',
    'doc_id': '6929221547142095',
  }

  response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
  response = json.loads(response.text)
  res = response
  
  cursor = None
  try: 
    cursor = response["data"]["feedback_hub_tab_items"]["page_info"]["end_cursor"]
  except:
    print("Cursor not found")

  if n > 0:
    n -= len(response["data"]["feedback_hub_tab_items"]["edges"])
  while (n > 0 or n == -1) and cursor != None:
    data = {
      'fb_dtsg': dtsg,
      'variables': f'{{"after":"{response["data"]["feedback_hub_tab_items"]["page_info"]["end_cursor"]}","first":10,"post_id":"{postID}","request_data":{{"sort_type":"most_recent","tab_type":"like"}}}}',
      'doc_id': '6929221547142095',
    }

    response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
    response = json.loads(response.text)
    cursor = response["data"]["feedback_hub_tab_items"]["page_info"]["end_cursor"]
    
    if len(response["data"]["feedback_hub_tab_items"]["edges"]) > 0:
      res["data"]["feedback_hub_tab_items"]["edges"].extend(response["data"]["feedback_hub_tab_items"]["edges"])
    else:
      break

    if n > 0:
      n -= len(response["data"]["feedback_hub_tab_items"]["edges"])
    sleep(delay)

  res["data"]["feedback_hub_tab_items"]["page_info"] = response["data"]["feedback_hub_tab_items"]["page_info"]
  print(len(res["data"]["feedback_hub_tab_items"]["edges"]))
  # res = ThreadsData.model_validate_json(json.dumps(res["data"]["feedback_hub_tab_items"], ensure_ascii=False))
  res = res["data"]["feedback_hub_tab_items"]["edges"]

  for node in res:
    user = node["node"]["actor"]
    res[res.index(node)] = user
  res = {"likers": res}
  print(res)

  return Likers.model_validate_json(json.dumps(res, ensure_ascii=False)).model_dump(mode='json', exclude_unset=True)


def get_reposters(postID: int, n: int = 100, delay: int = 1, dtsg: str = None, session_id: str = None) -> Json:

  '''
  Collects all (or up to n) users who reposted a post, sorted by most recent.

  Args:
    postID (int): Unique numerical identifier of a post.
    n (int): Maximum amount of reposters to return.
    dtsg (str): Value generated by Meta to validated the session.
    session_id (str): Cookie identifier for the user session.
    limit (int): Limit size of threads to crawl.
    delay (int): Delay among requests to avoid the account of getting suspended by bot activity.

  Returns:
     Json (List (User)): List of users object containing information about users who reposted the post
  '''


  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")
  
  
  cookies = {
    'sessionid': session_id,
  }

  data = {
    'fb_dtsg': dtsg,
    'variables': f'{{"first":10,"post_id":"{postID}","request_data":{{"sort_type":"most_recent","tab_type":"repost"}}}}',
    'doc_id': '6929221547142095',
  }

  response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
  print(response.text)
  response = json.loads(response.text)
  res = response
  
  cursor = None
  try: 
    cursor = response["data"]["feedback_hub_tab_items"]["page_info"]["end_cursor"]
  except:
    print("Cursor not found")

  if n > 0:
    n -= len(response["data"]["feedback_hub_tab_items"]["edges"])
  while (n > 0 or n == -1) and cursor != None:
    data = {
      'fb_dtsg': dtsg,
      'variables': f'{{"after":"{response["data"]["feedback_hub_tab_items"]["page_info"]["end_cursor"]}","first":10,"post_id":"{postID}","request_data":{{"sort_type":"most_recent","tab_type":"repost"}}}}',
      'doc_id': '6929221547142095',
    }

    response = requests.post('https://www.threads.net/api/graphql', cookies=cookies, headers=headers, data=data)
    response = json.loads(response.text)
    cursor = response["data"]["feedback_hub_tab_items"]["page_info"]["end_cursor"]
    
    if len(response["data"]["feedback_hub_tab_items"]["edges"]) > 0:
      res["data"]["feedback_hub_tab_items"]["edges"].extend(response["data"]["feedback_hub_tab_items"]["edges"])
    else:
      break

    if n > 0:
      n -= len(response["data"]["feedback_hub_tab_items"]["edges"])
    sleep(delay)

  res["data"]["feedback_hub_tab_items"]["page_info"] = response["data"]["feedback_hub_tab_items"]["page_info"]
  print(len(res["data"]["feedback_hub_tab_items"]["edges"]))
    # res = ThreadsData.model_validate_json(json.dumps(res["data"]["feedback_hub_tab_items"], ensure_ascii=False))

  res = res["data"]["feedback_hub_tab_items"]["edges"]

  for node in res:
    user = node["node"]["actor"]
    res[res.index(node)] = user
  res = {"likers": res}
  print(res)

  return Likers.model_validate_json(json.dumps(res, ensure_ascii=False)).model_dump(mode='json', exclude_unset=True)

def get_quotes(postID: int, n: int = 100, dtsg: str = None, session_id: str = None) -> Json:
  
    '''
    Collects all (or up to n) quotes and the users who quoted a post, sorted by most recent.
  
    Args:
      postID (int): Unique numerical identifier of a post.
      n (int): Maximum amount of quoters to return.
      dtsg (str): Value generated by Meta to validated the session.
      session_id (str): Cookie identifier for the user session.
      limit (int): Limit size of threads to crawl.
      delay (int): Delay among requests to avoid the account of getting suspended by bot activity.
  
    Returns:
      Json (List (User)): List of users object containing information about users who quoted the post
    '''
  
  
    if dtsg == None:
      dtsg = os.getenv("DTSG")
    
    if session_id == None:
      session_id = os.getenv("SESSION")
    pass

def download_media(postID:int,  path: str = None, dtsg: str = None, session_id: str = None) -> bool:

  '''
  Downloads the media of a post in the current or specified path

  Args:
    postID (int): Unique numerical identifier of a post.
    path (str): Path to save the media.
    dtsg (str): Value generated by Meta to validated the session.
    session_id (str): Cookie identifier for the user session.

  Returns:
    bool: True if the media was downloaded successfully, False otherwise.
  '''

  if dtsg == None:
    dtsg = os.getenv("DTSG")
  
  if session_id == None:
    session_id = os.getenv("SESSION")
  
  if path == None:
    path = os.getenv("MEDIA_PATH")
  
  pass